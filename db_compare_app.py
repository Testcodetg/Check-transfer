import json
from pathlib import Path
from typing import List, Dict, Tuple, Optional

import pyodbc
import pandas as pd
import streamlit as st

# ================================
# Paths/Constants
# ================================
CONFIG_PATH = Path("config.json")     # ‡∏°‡∏µ old_db/new_db/driver/encrypt/trust_server_cert
TABLES_PATH = Path("tables.json")     # {"master":[...], "transaction":[...]}

# ================================
# Base Utils
# ================================
def quote_ident(name: str) -> str:
    """‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ä‡∏∑‡πà‡∏≠ object ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏©"""
    return f"[{name.replace(']', ']]')}]"

def load_json(path: Path, default) -> dict:
    if not path.exists():
        path.write_text(json.dumps(default, ensure_ascii=False, indent=2), encoding="utf-8")
        return default
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception as e:
        st.error(f"‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå {path.name} ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
        return default

def save_json(path: Path, data: dict) -> bool:
    try:
        path.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
        return True
    except Exception as e:
        st.error(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å {path.name} ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
        return False

# ================================
# Config / Tables
# ================================
def load_config() -> dict:
    default_cfg = {
        "old_db": {"server": "", "database": "", "uid": "", "pwd": ""},
        "new_db": {"server": "", "database": "", "uid": "", "pwd": ""},
        "driver": "ODBC Driver 18 for SQL Server",
        "encrypt": True,
        "trust_server_cert": True,
    }
    return load_json(CONFIG_PATH, default_cfg)

def load_tables() -> dict:
    default_tables = {
        "master": ["PNM_Zone", "PNM_Province", "COM_Company", "DOC_DocumentName"],
        "transaction": ["DOC_Header", "DOC_Detail", "PNM_Position_His"],
    }
    return load_json(TABLES_PATH, default_tables)

def build_conn_str(cfg: dict, which: str) -> str:
    """
    which: 'old_db' | 'new_db'
    """
    driver = cfg.get("driver") or "ODBC Driver 18 for SQL Server"
    encrypt = "yes" if cfg.get("encrypt", True) else "no"
    trust = "yes" if cfg.get("trust_server_cert", True) else "no"

    part = cfg.get(which, {})
    server = part.get("server", "")
    database = part.get("database", "")
    uid = part.get("uid", "")
    pwd = part.get("pwd", "")

    return (
        f"DRIVER={{{driver}}};SERVER={server};DATABASE={database};"
        f"UID={uid};PWD={pwd};Encrypt={encrypt};TrustServerCertificate={trust}"
    )

def open_conn(conn_str: str):
    return pyodbc.connect(conn_str, timeout=10)

# ================================
# DB Metadata / Quick Checks
# ================================
def q_columns(conn, table_name: str) -> List[Tuple[str, int]]:
    """
    ‡∏Ñ‡∏∑‡∏ô [(column_name, column_id)] ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á
    """
    sql = """
    SELECT c.name AS col_name, c.column_id
    FROM sys.columns c
    INNER JOIN sys.objects o ON c.object_id = o.object_id
    WHERE o.type IN ('U') AND o.name = ?
    ORDER BY c.column_id
    """
    with conn.cursor() as cur:
        cur.execute(sql, (table_name,))
        return [(r[0], int(r[1])) for r in cur.fetchall()]

def q_rowcount(conn, table_name: str) -> int:
    sql = f"SELECT COUNT_BIG(1) FROM {quote_ident(table_name)} WITH (NOLOCK)"
    with conn.cursor() as cur:
        cur.execute(sql)
        return int(cur.fetchone()[0])

def q_checksum(conn, table_name: str) -> int:
    """
    SUM(BINARY_CHECKSUM(*)) ‚Äî ‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏û‡∏≠‡∏à‡∏±‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÑ‡∏î‡πâ (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 100% ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ó‡∏∏‡∏Å‡πÅ‡∏ñ‡∏ß‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå)
    """
    sql = f"SELECT ISNULL(SUM(BINARY_CHECKSUM(*)), 0) FROM {quote_ident(table_name)} WITH (NOLOCK)"
    with conn.cursor() as cur:
        cur.execute(sql)
        return int(cur.fetchone()[0])

def common_columns(conn_old, conn_new, table_name: str) -> List[str]:
    cols_old = [c for c, _ in q_columns(conn_old, table_name)]
    cols_new = [c for c, _ in q_columns(conn_new, table_name)]
    return [c for c in cols_old if c in cols_new]  # ‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏° OLD

# ================================
# Compare Logic
# ================================
def compare_table(conn_old, conn_new, table_name: str) -> dict:
    """
    ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö schema (‡πÅ‡∏Ñ‡πà‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå/‡∏•‡∏≥‡∏î‡∏±‡∏ö), row count, checksum
    ‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á -> ‡∏î‡∏∂‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≤‡∏á (‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡πà‡∏ß‡∏°) ‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÉ‡∏ô Python
    """
    res = {
        "table": table_name,
        "schema_equal": True,
        "rowcount_old": None,
        "rowcount_new": None,
        "checksum_old": None,
        "checksum_new": None,
        "ok": True,                 # true = ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (rowcount/checksum ‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô)
        "messages": [],
        "only_in_old": [],
        "only_in_new": [],
        "columns_used": [],
    }

    try:
        cols_old = [c for c, _ in q_columns(conn_old, table_name)]
        cols_new = [c for c, _ in q_columns(conn_new, table_name)]
        if cols_old != cols_new:
            res["schema_equal"] = False
            miss_new = [c for c in cols_old if c not in cols_new]
            miss_old = [c for c in cols_new if c not in cols_old]
            if miss_new:
                res["messages"].append(f"‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô OLD ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô NEW: {', '.join(miss_new)}")
            if miss_old:
                res["messages"].append(f"‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏ô NEW ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ô OLD: {', '.join(miss_old)}")

        res["rowcount_old"] = q_rowcount(conn_old, table_name)
        res["rowcount_new"] = q_rowcount(conn_new, table_name)
        if res["rowcount_old"] != res["rowcount_new"]:
            res["ok"] = False
            res["messages"].append(f"Row count ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô (OLD={res['rowcount_old']}, NEW={res['rowcount_new']})")

        res["checksum_old"] = q_checksum(conn_old, table_name)
        res["checksum_new"] = q_checksum(conn_new, table_name)
        if res["checksum_old"] != res["checksum_new"]:
            res["ok"] = False
            res["messages"].append("Checksum ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô")

        # ‡∏ñ‡πâ‡∏≤ checksum/rowcount ‡∏ï‡πà‡∏≤‡∏á -> ‡∏™‡∏∏‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡πÅ‡∏ö‡∏ö set-based ‡∏à‡∏≤‡∏Å 2 ‡∏ù‡∏±‡πà‡∏á
        if not res["ok"]:
            only_old, only_new, cols_used = sample_row_diffs(conn_old, conn_new, table_name, limit=100)
            res["only_in_old"] = only_old
            res["only_in_new"] = only_new
            res["columns_used"] = cols_used

        return res
    except Exception as e:
        res["ok"] = False
        res["messages"].append(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        return res

def sample_row_diffs(conn_old, conn_new, table: str, limit: int = 100) -> Tuple[List[Dict], List[Dict], List[str]]:
    """
    ‡∏î‡∏∂‡∏á sample ‡∏™‡∏≠‡∏á‡∏ä‡∏∏‡∏î‡∏à‡∏≤‡∏Å OLD/NEW ‡πÅ‡∏•‡∏∞‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏Ñ‡πà‡∏≤ (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡πà‡∏ß‡∏°)
    """
    cols = common_columns(conn_old, conn_new, table)
    if not cols:
        return [], [], []

    df_old = fetch_table_sample(conn_old, table, columns=cols, top=limit)
    df_new = fetch_table_sample(conn_new, table, columns=cols, top=limit)

    # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∏‡∏î tuples (‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô string ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢)
    cols_use = [c for c in cols if c in df_old.columns and c in df_new.columns]
    set_old = {tuple(str(x) for x in row) for row in df_old[cols_use].itertuples(index=False, name=None)}
    set_new = {tuple(str(x) for x in row) for row in df_new[cols_use].itertuples(index=False, name=None)}

    only_old = list(set_old - set_new)
    only_new = list(set_new - set_old)

    def to_dicts(tuples_list):
        return [dict(zip(cols_use, t)) for t in tuples_list][:limit]

    return to_dicts(only_old), to_dicts(only_new), cols_use

# ================================
# Data Preview
# ================================
def fetch_table_sample(conn, table: str,
                       columns: Optional[List[str]] = None,
                       where: Optional[str] = None,
                       order_by: Optional[str] = None,
                       top: int = 200) -> pd.DataFrame:
    cols_meta = q_columns(conn, table)
    all_cols = [c for c, _ in cols_meta]
    if not all_cols:
        return pd.DataFrame()

    use_cols = [c for c in (columns or all_cols) if c in all_cols] or all_cols
    col_sql = ", ".join(quote_ident(c) for c in use_cols)
    where_sql = f" WHERE {where} " if where and where.strip() else ""
    order_sql = f" ORDER BY {order_by} " if order_by and order_by.strip() else ""

    sql = f"SELECT TOP ({top}) {col_sql} FROM {quote_ident(table)} WITH (NOLOCK){where_sql}{order_sql}"

    with conn.cursor() as cur:
        cur.execute(sql)
        rows = cur.fetchall()
        df = pd.DataFrame.from_records(rows, columns=use_cols)
    return df

# ================================
# Streamlit UI
# ================================
st.set_page_config(page_title="DB Compare (Old vs New)", page_icon="üß™", layout="wide")
st.title("üß™ ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: ‡∏ê‡∏≤‡∏ô‡πÄ‡∏Å‡πà‡∏≤ vs ‡∏ê‡∏≤‡∏ô‡πÉ‡∏´‡∏°‡πà")

cfg = load_config()
tables = load_tables()

# ---- Connection Status
conn_str_old = build_conn_str(cfg, "old_db")
conn_str_new = build_conn_str(cfg, "new_db")

col_status, col_edit_tables = st.columns([1, 1])
with col_status:
    st.subheader("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠")
    ok_old = ok_new = False
    try:
        with open_conn(conn_str_old):
            st.success("OLD: ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ")
            ok_old = True
    except Exception as e:
        st.error(f"OLD: ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ - {e}")

    try:
        with open_conn(conn_str_new):
            st.success("NEW: ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ")
            ok_new = True
    except Exception as e:
        st.error(f"NEW: ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ - {e}")

with col_edit_tables:
    st.subheader("‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ tables.json")
    tables_editor = st.text_area("‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ï‡∏≤‡∏£‡∏≤‡∏á", value=json.dumps(tables, ensure_ascii=False, indent=2), height=200)
    if st.button("üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å tables.json"):
        try:
            new_tbls = json.loads(tables_editor)
            if save_json(TABLES_PATH, new_tbls):
                st.success("‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
                st.experimental_rerun()
        except Exception as e:
            st.error(f"‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {e}")

st.divider()

# ---- Compare Section
st.header("üîç Compare (Schema/Rows/Checksum)")

tab_choice = st.radio("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏°‡∏ß‡∏î", options=["master", "transaction"], horizontal=True, key="cmp_cat")
options = tables.get(tab_choice, [])
selected = st.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö", options=options, default=options)

if st.button("‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö", disabled=not (ok_old and ok_new)):
    if not selected:
        st.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏ï‡∏≤‡∏£‡∏≤‡∏á")
    else:
        with open_conn(conn_str_old) as conn_old, open_conn(conn_str_new) as conn_new:
            for tname in selected:
                st.markdown(f"### üìÑ ‡∏ï‡∏≤‡∏£‡∏≤‡∏á: `{tname}`")
                res = compare_table(conn_old, conn_new, tname)

                if res["ok"] and res["schema_equal"]:
                    status = "‚úÖ ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î"
                elif res["ok"] and not res["schema_equal"]:
                    status = "üü° ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ ‡πÅ‡∏ï‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏≤‡∏à‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô"
                else:
                    status = "‚ùå ‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á"

                st.write(f"‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö: **{status}**")
                st.write(
                    f"- Schema equal: **{res['schema_equal']}**  \n"
                    f"- RowCount: OLD = **{res['rowcount_old']}**, NEW = **{res['rowcount_new']}**  \n"
                    f"- Checksum: OLD = **{res['checksum_old']}**, NEW = **{res['checksum_new']}**"
                )
                if res["messages"]:
                    with st.expander("‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î / ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô"):
                        for m in res["messages"]:
                            st.write(f"- {m}")

                if not res["ok"]:
                    c1, c2 = st.columns(2)
                    with c1:
                        st.subheader("üîª ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô OLD ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô NEW (sample)")
                        if res["only_in_old"]:
                            st.dataframe(pd.DataFrame(res["only_in_old"]), use_container_width=True)
                            csv1 = pd.DataFrame(res["only_in_old"]).to_csv(index=False).encode("utf-8-sig")
                            st.download_button("‚¨áÔ∏è CSV (Only in OLD - sample)", data=csv1,
                                               file_name=f"{tname}_only_in_OLD_sample.csv", mime="text/csv")
                        else:
                            st.caption("‚Äî ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ‚Äî")
                    with c2:
                        st.subheader("üî∫ ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô NEW ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô OLD (sample)")
                        if res["only_in_new"]:
                            st.dataframe(pd.DataFrame(res["only_in_new"]), use_container_width=True)
                            csv2 = pd.DataFrame(res["only_in_new"]).to_csv(index=False).encode("utf-8-sig")
                            st.download_button("‚¨áÔ∏è CSV (Only in NEW - sample)", data=csv2,
                                               file_name=f"{tname}_only_in_NEW_sample.csv", mime="text/csv")
                        else:
                            st.caption("‚Äî ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á ‚Äî")
                st.divider()

st.divider()

# ---- Data Preview Section
st.header("üëÄ ‡∏î‡∏π‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏£‡∏≤‡∏á (Data Preview)")
prev_cat = st.radio("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏°‡∏ß‡∏î", options=["master", "transaction"], horizontal=True, key="preview_cat")
prev_options = tables.get(prev_cat, [])
tbl_preview = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á", options=prev_options, index=0 if prev_options else None)

if tbl_preview and ok_old and ok_new:
    with open_conn(conn_str_old) as conn_old, open_conn(conn_str_new) as conn_new:
        cols_old = [c for c, _ in q_columns(conn_old, tbl_preview)]
        cols_new = [c for c, _ in q_columns(conn_new, tbl_preview)]
        common_cols = [c for c in cols_old if c in cols_new] or (cols_old or cols_new)

        st.subheader(f"‡∏ï‡∏≤‡∏£‡∏≤‡∏á: `{tbl_preview}`")
        with st.expander("üß© ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", expanded=True):
            c_l, c_r = st.columns([2, 1])
            with c_l:
                picked_cols = st.multiselect("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (‡πÄ‡∏ß‡πâ‡∏ô‡∏ß‡πà‡∏≤‡∏á = ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡πà‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)",
                                             options=common_cols,
                                             default=common_cols[:min(10, len(common_cols))])
                where_clause = st.text_input("WHERE (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ WHERE)", placeholder="‡πÄ‡∏ä‡πà‡∏ô Code='TH' AND IsActive=1")
                order_by = st.text_input("ORDER BY", placeholder="‡πÄ‡∏ä‡πà‡∏ô Code, Name")
            with c_r:
                top_n = st.number_input("TOP (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß)", min_value=1, max_value=100000, value=200, step=50)
                st.caption("‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ 50‚Äì1000 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÄ‡∏£‡πá‡∏ß")

            run_preview = st.button("üìÑ ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (OLD/NEW)")

        if run_preview:
            col_old, col_new = st.columns(2)
            use_cols = picked_cols or common_cols

            with col_old:
                st.write("**OLD**")
                try:
                    df_old = fetch_table_sample(conn_old, tbl_preview, use_cols, where_clause, order_by, top_n)
                    st.dataframe(df_old, use_container_width=True)
                    st.download_button("‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV (OLD)",
                                       data=df_old.to_csv(index=False).encode("utf-8-sig"),
                                       file_name=f"{tbl_preview}_OLD.csv",
                                       mime="text/csv")
                except Exception as e:
                    st.error(f"‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• OLD ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

            with col_new:
                st.write("**NEW**")
                try:
                    df_new = fetch_table_sample(conn_new, tbl_preview, use_cols, where_clause, order_by, top_n)
                    st.dataframe(df_new, use_container_width=True)
                    st.download_button("‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV (NEW)",
                                       data=df_new.to_csv(index=False).encode("utf-8-sig"),
                                       file_name=f"{tbl_preview}_NEW.csv",
                                       mime="text/csv")
                except Exception as e:
                    st.error(f"‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• NEW ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")

        with st.expander("üß™ ‡∏ï‡∏±‡∏ß‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏ß (diff ‡∏à‡∏≤‡∏Å sample ‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤)"):
            st.caption("‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô (‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå/WHERE/ORDER/TOP) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á sample ‡πÅ‡∏•‡∏∞‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô")
            if st.button("üîç ‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô (from sample)"):
                try:
                    use_cols = picked_cols or common_cols
                    df_old = fetch_table_sample(conn_old, tbl_preview, use_cols, where_clause, order_by, top_n)
                    df_new = fetch_table_sample(conn_new, tbl_preview, use_cols, where_clause, order_by, top_n)

                    cols_use = [c for c in use_cols if c in df_old.columns and c in df_new.columns]
                    if not cols_use:
                        st.warning("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡πà‡∏ß‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö")
                    else:
                        set_old = {tuple(str(x) for x in row) for row in df_old[cols_use].itertuples(index=False, name=None)}
                        set_new = {tuple(str(x) for x in row) for row in df_new[cols_use].itertuples(index=False, name=None)}
                        only_old = set_old - set_new
                        only_new = set_new - set_old

                        def tuples_to_df(tset):
                            return pd.DataFrame([dict(zip(cols_use, t)) for t in list(tset)])

                        c1, c2 = st.columns(2)
                        with c1:
                            st.write("üîª ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô OLD ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô NEW (‡∏à‡∏≤‡∏Å sample)")
                            df1 = tuples_to_df(only_old)
                            st.dataframe(df1, use_container_width=True)
                            if not df1.empty:
                                st.download_button("‚¨áÔ∏è CSV (Only in OLD - sample)",
                                                   data=df1.to_csv(index=False).encode("utf-8-sig"),
                                                   file_name=f"{tbl_preview}_only_in_OLD_sample.csv",
                                                   mime="text/csv")
                        with c2:
                            st.write("üî∫ ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô NEW ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô OLD (‡∏à‡∏≤‡∏Å sample)")
                            df2 = tuples_to_df(only_new)
                            st.dataframe(df2, use_container_width=True)
                            if not df2.empty:
                                st.download_button("‚¨áÔ∏è CSV (Only in NEW - sample)",
                                                   data=df2.to_csv(index=False).encode("utf-8-sig"),
                                                   file_name=f"{tbl_preview}_only_in_NEW_sample.csv",
                                                   mime="text/csv")
                except Exception as e:
                    st.error(f"‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
else:
    if not ok_old or not ok_new:
        st.info("‡∏¢‡∏±‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö config.json ‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤ '‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠' ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏≥‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤")

# ================================
# Notes
# ================================
st.caption(
    "‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ WITH (NOLOCK) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏•‡πá‡∏≠‡∏Å ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö/‡∏≠‡πà‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß "
    "‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ò‡∏∏‡∏£‡∏Å‡∏£‡∏£‡∏° 100% ‡πÉ‡∏´‡πâ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡πÄ‡∏≠‡∏≤ NOLOCK ‡∏≠‡∏≠‡∏Å‡∏ï‡∏≤‡∏°‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°."
)
